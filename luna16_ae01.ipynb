{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage, misc\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Dropout, GaussianNoise\n",
    "from keras.layers import Convolution2D, Deconvolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Convolution3D, UpSampling3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import backend as K_backend\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import ipyvolume as ipv\n",
    "\n",
    "import autoencoder\n",
    "\n",
    "# Need this because otherwise the progbar freezes my Jupyter\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Dropout\n",
    "from keras.layers import Conv1D, Conv2D, UpSampling1D, UpSampling2D, Conv2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K_backend\n",
    "from keras import objectives\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "\n",
    "class Autoencoder(object):\n",
    "    def __init__(self,\n",
    "                 input_shape=(28, 28, 1),\n",
    "                 latent_dim=2,  # Size of the encoded vector\n",
    "                 batch_size=100): # size of minibatch\n",
    "        self.model = None\n",
    "        self.encoder = None\n",
    "        self.generator = None\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        assert K_backend.image_dim_ordering() == 'tf', 'Cannot support Theano ordering! Use TF ordering! #tensorflowmasterrace'\n",
    "        \n",
    "    def unroll_decoder(self, z, z_input, layers_list):\n",
    "        \"\"\"Takes a list of Keras layers and returns the decoder back-half and the standalone decoder model\"\"\"\n",
    "        ae = AE_Dec()\n",
    "        dc = AE_Dec()\n",
    "        last_ae = z\n",
    "        last_dc = z_input\n",
    "        for i, layer in enumerate(layers_list):\n",
    "#             if i ==0:\n",
    "            last_ae = layer(last_ae)\n",
    "            last_dc = layer(last_dc)\n",
    "        return last_ae, last_dc\n",
    "        \n",
    "class AE_Dec(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "class VAE(Autoencoder):\n",
    "    def __init__(self,\n",
    "                 input_shape=(28, 28, 1),\n",
    "                 latent_dim=2,  # Size of the encoded vector\n",
    "                 batch_size=100,  # size of minibatch\n",
    "                 epsilon_std=1.0):  # This is the stddev for our normal-dist sampling of the latent vector):\n",
    "        super().__init__(input_shape=input_shape, latent_dim=latent_dim, batch_size=batch_size)\n",
    "        # Necessary to instantiate this as instance variables such that they can be passed to the loss function (internally), since loss functions are \n",
    "        # all of the form lossfn(y_true, y_pred)\n",
    "        self.epsilon_std = epsilon_std\n",
    "        self.z_mean = Dense(latent_dim)\n",
    "        self.z_log_var = Dense(latent_dim)\n",
    "\n",
    "        # input image dimensions\n",
    "        self.input_shape = input_shape\n",
    "        if len(input_shape) == 4:\n",
    "            self.img_rows, self.img_cols, self.img_stacks, self.img_chns = input_shape\n",
    "        elif len(input_shape) == 3:\n",
    "            self.img_rows, self.img_cols, self.img_chns = input_shape\n",
    "        elif len(input_shape) == 2:\n",
    "            self.img_rows, self.img_cols = input_shape\n",
    "            self.img_chns = 1\n",
    "        elif len(input_shape) == 1:\n",
    "            self.img_rows = input_shape[0] # todo: test this\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input shape: {}\".format(input_shape))\n",
    "\n",
    "\n",
    "    def sampling(self, args):\n",
    "        # Forging our latent vector from the reparameterized mean and std requires some sampling trickery\n",
    "        # that admittedly I do not understand in the slightest at this point in time\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K_backend.random_normal(shape=(self.batch_size, self.latent_dim),\n",
    "                                          mean=0., stddev=self.epsilon_std)\n",
    "        # We return z_mean + epsilon*sigma^2. Not sure why we use log var\n",
    "        # Basically, create a random variable vector from the distribution\n",
    "        # We are learning a distribution (mu, var) which represents the input\n",
    "        return z_mean + K_backend.exp(z_log_var) * epsilon\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        # Custom loss function for VAE. More VAE voodoo\n",
    "        # FC: NOTE: binary_crossentropy expects a shape (batch_size, dim)\n",
    "        # FC: for x and x_decoded_mean, so we MUST flatten these!\n",
    "        x = K_backend.flatten(x)\n",
    "        x_decoded_mean = K_backend.flatten(x_decoded_mean)\n",
    "        shape_coef = self.img_rows * self.img_cols # this needs an update for dimensionality!\n",
    "        xent_loss =  shape_coef * objectives.binary_crossentropy(x, x_decoded_mean) \n",
    "        kl_loss = - 0.5 * K_backend.mean(\n",
    "            1 + self.z_log_var - K_backend.square(self.z_mean) - K_backend.exp(self.z_log_var), axis=-1)\n",
    "        # Kullbackâ€“Leibler divergence. so many questions about this one single line\n",
    "        return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Convo3d(object):\n",
    "    def __init__(self, input_shape=(28, 28, 28, 1), n_classes=10, n_filters=4):\n",
    "        \"\"\"\n",
    "        5D tensor with shape: (samples, channels, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th' or \n",
    "        5D tensor with shape: (samples, conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'.\n",
    "        \"\"\"\n",
    "#         input_img = Input(shape=(1, 28, 28, 28)) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        input_img = Input(shape=input_shape) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        img_chans = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        x = Convolution3D(n_filters, 3, 3, 3, activation='relu', border_mode='same', name='Conv_1')(input_img)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same', name='Pool_1')(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same', name='Conv_2')(x)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same', name='Pool_2')(x)\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same', name='Conv_3')(x)\n",
    "        pooled = MaxPooling3D((2, 2, 2), border_mode='same', name='Pool_3')(x)\n",
    "        self.pooled = pooled\n",
    "        # at this point the representation is (4, 4, 4, 8) i.e. 512-dimensional\n",
    "#         print('Pooled shape: ', pooled.shape)\n",
    "        flat = Flatten()(pooled)\n",
    "#         z = Dense(n_classes)\n",
    "        classer_base = Dense(n_classes, init='normal', activation='softmax', name='classer_output')(flat)\n",
    "    \n",
    "        self.z = pooled # hack\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same', name='Deconv_3')(self.z)\n",
    "        x = UpSampling3D((2, 2, 2), name='Upsamp_3')(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same', name='Deconv_2')(x)\n",
    "        x = UpSampling3D((2, 2, 2), name='Upsamp_2')(x)\n",
    "#         x = Convolution3D(16, 3, 3, 3, activation='relu', border_mode='valid')(x)\n",
    "        x = UpSampling3D((2, 2, 2), name='Upsamp_1')(x)\n",
    "        # smash the extra channels down\n",
    "        x = Convolution3D(img_chans, 3, 3, 3, activation='sigmoid', border_mode='same', name='Deconv_1')(x)\n",
    "#         print(input_shape)\n",
    "#         x = Dense(input_shape)(x) # fudge to fix output shape\n",
    "        self.decoded = x\n",
    "        self.autoencoder = Model(input_img, self.decoded)\n",
    "        \n",
    "        self.classifier = Model(input_img, classer_base)\n",
    "        self.classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class YAConvo3d(object):\n",
    "    def __init__(self, input_shape=(28, 28, 28, 1), n_classes=10, n_filters=4):\n",
    "        \"\"\"\n",
    "        5D tensor with shape: (samples, channels, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th' or \n",
    "        5D tensor with shape: (samples, conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'.\n",
    "        \"\"\"\n",
    "#         input_img = Input(shape=(1, 28, 28, 28)) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        input_img = Input(shape=input_shape) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        img_chans = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        x = Convolution3D(n_filters, 3, 3, 3, activation='relu', border_mode='same', name='Conv_1')(input_img)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same', name='Pool_1')(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same', name='Conv_2')(x)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same', name='Pool_2')(x)\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same', name='Conv_3')(x)\n",
    "        pooled = MaxPooling3D((2, 2, 2), border_mode='same', name='Pool_3')(x)\n",
    "        self.pooled = pooled\n",
    "        # at this point the representation is (4, 4, 4, 8) i.e. 512-dimensional\n",
    "#         print('Pooled shape: ', pooled.shape)\n",
    "        flat = Flatten()(pooled)\n",
    "#         z = Dense(n_classes)\n",
    "        classer_base = Dense(n_classes, init='normal', activation='softmax', name='classer_output')(flat)\n",
    "    \n",
    "        self.z = pooled # hack\n",
    "        \n",
    "        decoder_reshape = Reshape((6,6,6,128))(flat)\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same', name='Deconv_3')(decoder_reshape)\n",
    "        x = UpSampling3D((2, 2, 2), name='Upsamp_3')(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same', name='Deconv_2')(x)\n",
    "        x = UpSampling3D((2, 2, 2), name='Upsamp_2')(x)\n",
    "#         x = Convolution3D(16, 3, 3, 3, activation='relu', border_mode='valid')(x)\n",
    "        x = UpSampling3D((2, 2, 2), name='Upsamp_1')(x)\n",
    "        # smash the extra channels down\n",
    "        x = Convolution3D(img_chans, 3, 3, 3, activation='sigmoid', border_mode='same', name='Deconv_1')(x)\n",
    "#         print(input_shape)\n",
    "#         x = Dense(input_shape)(x) # fudge to fix output shape\n",
    "        self.decoded = x\n",
    "        self.autoencoder = Model(input_img, self.decoded)\n",
    "        \n",
    "        self.classifier = Model(input_img, classer_base)\n",
    "        self.classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Vae3D(VAE):\n",
    "    def __init__(self, input_shape=(28, 28, 28, 1), latent_dim=2, batch_size=100, n_classes=10, n_filters=4):\n",
    "        \"\"\"\n",
    "        5D tensor with shape: (samples, channels, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th' or \n",
    "        5D tensor with shape: (samples, conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'.\n",
    "        \"\"\"\n",
    "#         input_img = Input(shape=(1, 28, 28, 28)) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        super().__init__(input_shape=input_shape, latent_dim=latent_dim, batch_size=batch_size)\n",
    "\n",
    "        T, U, V, CH = input_shape\n",
    "        input_img = Input(shape=input_shape) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        img_chans = 1\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "\n",
    "        \n",
    "        x = Convolution3D(n_filters, 3, 3, 3, activation='relu', border_mode='same')(input_img)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same')(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same')(x)\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "        pooled = MaxPooling3D((2, 2, 2), border_mode='same')(x)\n",
    "\n",
    "        # at this point the representation is (4, 4, 4, 8) i.e. 512-dimensional\n",
    "        flat = Flatten()(pooled)\n",
    "        \n",
    "        hidden_1 = Dense(latent_dim*2, activation='relu', name='intermezzo')(flat) # CNN conversion layer, not really necessary here\n",
    "        # One weird VAE trick\n",
    "        z_mean = Dense(latent_dim, name='Z_mean')(hidden_1)\n",
    "        z_log_var = Dense(latent_dim, name='Z_log_var')(hidden_1)\n",
    "        self.z_mean = z_mean\n",
    "        self.z_log_var = z_log_var\n",
    "        z = Lambda(self.sampling, output_shape=(latent_dim,), name='latent_z')([z_mean, z_log_var])\n",
    "\n",
    "#         classer_base = Dense(n_classes, init='normal', activation='softmax', name='classer_output')(flat)\n",
    "        dec_hidden = Dense(latent_dim*2, activation='relu', name='Dec_intermezzo')\n",
    "        decoder_upsample = Dense(n_filters * (T*U*V/8), activation='relu')\n",
    "        \n",
    "        decoder_reshape = Reshape((6,6,6,128))\n",
    "\n",
    "        dec_cnn_3 = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same')\n",
    "        dec_ups_3 = UpSampling3D((2, 2, 2))\n",
    "        dec_cnn_2 = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same')\n",
    "        dec_ups_2 = UpSampling3D((2, 2, 2))\n",
    "#         x = Convolution3D(16, 3, 3, 3, activation='relu', border_mode='valid')(x)\n",
    "        dec_cnn_1 = UpSampling3D((2, 2, 2))\n",
    "        # smash the extra channels down\n",
    "        dec_ups_1 = Convolution3D(img_chans, 3, 3, 3, activation='sigmoid', border_mode='same')\n",
    "#         print(input_shape)\n",
    "#         x = Dense(input_shape)(x) # fudge to fix output shape\n",
    "        layers_list = []\n",
    "#         ae, dc = self.unroll_decoder(z, )\n",
    "        \n",
    "        self.decoded = x\n",
    "        self.autoencoder = Model(input_img, self.decoded)\n",
    "        \n",
    "#         self.classifier = Model(input_img, classer_base)\n",
    "#         self.classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 48, 48, 48, 1)     0         \n",
      "_________________________________________________________________\n",
      "Conv_1 (Conv3D)              (None, 48, 48, 48, 8)     224       \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling3D)        (None, 24, 24, 24, 8)     0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv3D)              (None, 24, 24, 24, 64)    13888     \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling3D)        (None, 12, 12, 12, 64)    0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv3D)              (None, 12, 12, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "Pool_3 (MaxPooling3D)        (None, 6, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 6, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "Deconv_3 (Conv3D)            (None, 6, 6, 6, 128)      442496    \n",
      "_________________________________________________________________\n",
      "Upsamp_3 (UpSampling3D)      (None, 12, 12, 12, 128)   0         \n",
      "_________________________________________________________________\n",
      "Deconv_2 (Conv3D)            (None, 12, 12, 12, 64)    221248    \n",
      "_________________________________________________________________\n",
      "Upsamp_2 (UpSampling3D)      (None, 24, 24, 24, 64)    0         \n",
      "_________________________________________________________________\n",
      "Upsamp_1 (UpSampling3D)      (None, 48, 48, 48, 64)    0         \n",
      "_________________________________________________________________\n",
      "Deconv_1 (Conv3D)            (None, 48, 48, 48, 1)     1729      \n",
      "=================================================================\n",
      "Total params: 900,897.0\n",
      "Trainable params: 900,897.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(8, (3, 3, 3), padding=\"same\", activation=\"relu\", name=\"Conv_1\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D((2, 2, 2), padding=\"same\", name=\"Pool_1\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:15: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\", name=\"Conv_2\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D((2, 2, 2), padding=\"same\", name=\"Pool_2\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), padding=\"same\", activation=\"relu\", name=\"Conv_3\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D((2, 2, 2), padding=\"same\", name=\"Pool_3\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, kernel_initializer=\"normal\", activation=\"softmax\", name=\"classer_output\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:29: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), padding=\"same\", activation=\"relu\", name=\"Deconv_3\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:31: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\", name=\"Deconv_2\")`\n",
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:36: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(1, (3, 3, 3), padding=\"same\", activation=\"sigmoid\", name=\"Deconv_1\")`\n"
     ]
    }
   ],
   "source": [
    "ae_base = YAConvo3d(input_shape=(48,48,48,1), n_filters=8)\n",
    "ae_base.autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert 0, halt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-233a3e5b0206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# data = np.array(data, dtype='int16')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "datas = []\n",
    "drive = 'tera'\n",
    "basepath = '/media/mike/{}/data/bowl17/luna/volumes_48/'.format(drive)\n",
    "for n in ['c', 'p']:\n",
    "    for i in range(3):\n",
    "        path = basepath + 'tumor_{}_volumes{:02}.npy'.format(n, i)\n",
    "        try:\n",
    "            f = np.load(path)\n",
    "            print(f.shape)\n",
    "            datas.append(f)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    \n",
    "data = np.concatenate(datas, axis=0)\n",
    "# data = np.array(data, dtype='int16')\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s = ae_base.pooled\n",
    "l = s(Dense(12))\n",
    "# s.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ae_base.autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = data.reshape((len(data), 48, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train = data.reshape((len(data), 48, 48, 48, 1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ae_base.autoencoder.fit(x_train, x_train, batch_size=20, nb_epoch=10, verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[3][24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = ae_base.autoencoder.predict(x_train, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred[3].reshape((48,48,48))[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
