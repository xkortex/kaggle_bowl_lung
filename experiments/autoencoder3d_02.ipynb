{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage, misc\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Dropout, GaussianNoise\n",
    "from keras.layers import Convolution2D, Deconvolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Convolution3D, UpSampling3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import backend as K_backend\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Need this because otherwise the progbar freezes my Jupyter\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from skimage import measure, morphology\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def nimshow(img):\n",
    "    plt.imshow(img, interpolation='none')\n",
    "    \n",
    "def conv(img, kern, renorm=False):\n",
    "    ift = signal.fftconvolve(img, kern, 'same')\n",
    "    if renorm:\n",
    "        ift /= np.amax(ift)\n",
    "    return ift\n",
    "\n",
    "def ricker2d(x, y, f=np.pi, n=0.5):\n",
    "    r = (x**2 + y**2)**n\n",
    "    return (1.0 - 2.0*(np.pi**2)*(f**2)*(r**2)) * np.exp(-(np.pi**2)*(f**2)*(r**2))\n",
    "\n",
    "def gauss2d(x, y, f=1, sig=1, n=0.5):\n",
    "    r = (x**2 + y**2)**n\n",
    "    return np.exp(-((f*r)**2)/(.25*sig**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_3d(image, threshold=-300, azim=45, elev=45):\n",
    "    \n",
    "    # Position the scan upright, \n",
    "    # so the head of the patient would be at the top facing the camera\n",
    "    p = image.transpose(2,1,0)\n",
    "#     p = p[:,:,::-1]\n",
    "    \n",
    "    verts, faces = measure.marching_cubes(p, threshold)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.1)\n",
    "    face_color = [0.5, 0.5, 1]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "    ax.azim = azim\n",
    "    ax.elev = elev\n",
    "\n",
    "    ax.set_xlim(0, p.shape[0])\n",
    "    ax.set_ylim(0, p.shape[1])\n",
    "    ax.set_zlim(0, p.shape[2])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def splay(volume, rows=5, cols=5):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    n = rows*cols\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            fig.add_subplot(rows, cols, cols*i+j+1)\n",
    "            plt.imshow(volume[cols*i+j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3d = np.load('/home/mike/py/kaggle/npdata/x_train_mnist3d_1k.npy')\n",
    "x_train3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "# x_train = np.reshape(x_train, (len(x_train), 1, 28, 28))\n",
    "# x_test = np.reshape(x_test, (len(x_test), 1, 28, 28))\n",
    "y_train_oh = np_utils.to_categorical(y_train)\n",
    "y_test_oh = np_utils.to_categorical(y_test)\n",
    "y_train_oh = y_train_oh[:len(x_train3d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# x_train3d_2x = sp.ndimage.zoom(x_train3d, (1,2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padcrop_vol(vol, newshape=[360, 360, 360]):\n",
    "    vol2 = np.array(vol)\n",
    "    shape = vol.shape\n",
    "    z, y, x = shape\n",
    "    mids = [d // 2 for d in shape]\n",
    "    for dim in range(3):\n",
    "        if shape[dim] < newshape[dim]:\n",
    "            pad_amt = (newshape[dim] - shape[dim]) // 2\n",
    "            parity = (shape[dim] & 1) ^ (newshape[dim] & 1)\n",
    "            pad_tup = (pad_amt, pad_amt + parity) # \n",
    "            pad_list = [(0,0), (0,0), (0,0)]\n",
    "            pad_list[dim] = pad_tup\n",
    "            vol2 = np.pad(vol2, pad_list, mode='constant', constant_values=0)\n",
    "        if shape[dim] > newshape[dim]:\n",
    "            slc_amt = (shape[dim] - newshape[dim]) // 2\n",
    "            parity = (shape[dim] & 1) ^ (newshape[dim] & 1)\n",
    "            slc_tup = (slc_amt, shape[dim] - slc_amt - parity) # \n",
    "            null1, vol2, null2 = np.split(vol2, slc_tup, dim)\n",
    "\n",
    "    return vol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train3d_48 = [padcrop_vol(v, (48,48,48)) for v in x_train3d]\n",
    "x_train3d_48 = np.array(x_train3d_48, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 48, 48, 48, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, x, y, z = x_train3d_48.shape\n",
    "x_train3d_48 = x_train3d_48.reshape((n, x, y, z, 1))\n",
    "x_train3d_48.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, x, y, z = x_train3d.shape\n",
    "x_train3d = x_train3d.reshape((n, x, y, z, 1))\n",
    "x_train3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# n, x, y, z = x_train3d_2x.shape\n",
    "# x_train3d_2x = x_train3d_2x.reshape((n, x, y, z, 1))\n",
    "# x_train3d_2x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Convo3d(object):\n",
    "    def __init__(self, input_shape=(28, 28, 28, 1), n_classes=10, n_filters=4):\n",
    "        \"\"\"\n",
    "        5D tensor with shape: (samples, channels, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th' or \n",
    "        5D tensor with shape: (samples, conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'.\n",
    "        \"\"\"\n",
    "#         input_img = Input(shape=(1, 28, 28, 28)) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        input_img = Input(shape=input_shape) # th =(nChan, nFrames, xPix, yPix) or (nChan, z, x, y)\n",
    "        img_chans = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        x = Convolution3D(n_filters, 3, 3, 3, activation='relu', border_mode='same')(input_img)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same')(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "        x = MaxPooling3D((2, 2, 2), border_mode='same')(x)\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "        self.z = MaxPooling3D((2, 2, 2), border_mode='same')(x)\n",
    "\n",
    "        # at this point the representation is (4, 4, 4, 8) i.e. 512-dimensional\n",
    "        \n",
    "        flat = Flatten()(self.z)\n",
    "        classer_base = Dense(n_classes, init='normal', activation='softmax', name='classer_output')(flat)\n",
    "\n",
    "        x = Convolution3D(n_filters*16, 3, 3, 3, activation='relu', border_mode='same')(self.z)\n",
    "        x = UpSampling3D((2, 2, 2))(x)\n",
    "        x = Convolution3D(n_filters*8, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "        x = UpSampling3D((2, 2, 2))(x)\n",
    "#         x = Convolution3D(16, 3, 3, 3, activation='relu', border_mode='valid')(x)\n",
    "        x = UpSampling3D((2, 2, 2))(x)\n",
    "        # smash the extra channels down\n",
    "        x = Convolution3D(img_chans, 3, 3, 3, activation='sigmoid', border_mode='same')(x)\n",
    "#         print(input_shape)\n",
    "#         x = Dense(input_shape)(x) # fudge to fix output shape\n",
    "        self.decoded = x\n",
    "        self.autoencoder = Model(input_img, self.decoded)\n",
    "        \n",
    "        self.classifier = Model(input_img, classer_base)\n",
    "        self.classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ae_base = Convo3d(x_train3d_48[0].shape)\n",
    "ae = ae_base.autoencoder\n",
    "ae.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 48, 48, 48, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_1 (Convolution3D)  (None, 48, 48, 48, 4) 112         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling3d_1 (MaxPooling3D)    (None, 24, 24, 24, 4) 0           convolution3d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_2 (Convolution3D)  (None, 24, 24, 24, 32 3488        maxpooling3d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling3d_2 (MaxPooling3D)    (None, 12, 12, 12, 32 0           convolution3d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_3 (Convolution3D)  (None, 12, 12, 12, 64 55360       maxpooling3d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling3d_3 (MaxPooling3D)    (None, 6, 6, 6, 64)   0           convolution3d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_4 (Convolution3D)  (None, 6, 6, 6, 64)   110656      maxpooling3d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "upsampling3d_1 (UpSampling3D)    (None, 12, 12, 12, 64 0           convolution3d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_5 (Convolution3D)  (None, 12, 12, 12, 32 55328       upsampling3d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "upsampling3d_2 (UpSampling3D)    (None, 24, 24, 24, 32 0           convolution3d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "upsampling3d_3 (UpSampling3D)    (None, 48, 48, 48, 32 0           upsampling3d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_6 (Convolution3D)  (None, 48, 48, 48, 1) 865         upsampling3d_3[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 225,809\n",
      "Trainable params: 225,809\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The limit for a 3D 3-layer convonet VAE conks out on this laptop at batch_size=100, 236,500 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor size: (1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1, 1000, 48, 48, 48, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39da6b666dd4812a8d5207592a7a8dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e11f4c5248f4c8a92d9592ad65c8b15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e094223c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=50\n",
    "x_train_n = x_train3d_48\n",
    "print('Tensor size: {}'.format(x_train_n.shape * batch_size))\n",
    "ae.fit(x_train_n, x_train_n, shuffle=True,batch_size=batch_size,\n",
    "               nb_epoch=1, \n",
    "               verbose=False, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5529600"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48**3 * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works:\n",
    "32^3 x 100 = 3276800\n",
    "48^3 x 50 = 5529600\n",
    "\n",
    "Does not work / questionable\n",
    "48^3 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec3ec7fa56b4938851bc5c37c749488"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bea7976bd114a84b8916cd209fe9084"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fc8019d8e347078f96324cfe30aa08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5a1e7b6f2849f7ab05e3180baeb728"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef43dd2abc0148d3aadb83c948c7551d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e147e84d6f3b4d0db58edf64eea41d35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e066cfe10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_base.classifier.fit(x_train_n, y_train_oh, shuffle=True,batch_size=batch_size,\n",
    "               nb_epoch=5, \n",
    "               verbose=False, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14330089798569678, 0.94699999999999995]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_base.classifier.evaluate(x_train_n, y_train_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "56**3 *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "041f95d3d3c3446090de12a64c15961b": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "0d451fd85c414529b6000341434f6ef2": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "0fd3f6ea6b504266a2a8c9a06e88ee9b": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "178b1031286f4c83b6e1b53d79914846": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1ac1327155514ad7b014167ef6add2b2": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "2a15da1d740d4d4983cca8813fea0251": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2e47803a32b84470b088b1082f41fa14": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "33325a9c7a3140ba97eab043328107fd": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "406551b1d0e940beaaaf2b8467f9ac5b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "56fa1a4355e44d288cd80425717d42b5": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "5e3972d347834df88508361b099aa7e4": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "687570a293ed4421b05d137d4735b333": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "782d0ab7964544c2972050ffb413828e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "83ae780cd202410992ef5ae17a5ed869": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "84f824e542884d5eb1b7f6922722b8b6": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "8b0f42b8cce8419abf6628b6d19975e6": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "8b859794c05d40e3a9f930fe17f59dc7": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "99e7ccb2a1c549d780142fba4dfd9167": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "9a1d86119d5e454aafcc4d1267c0ea4a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "9b8955ba45d4446084b8018e0ca0ce48": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "adbff67dae344a01875923bc90777805": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "be6e6e1322e24728962ecec2893440a8": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "c884a412921b4267862279a38427fd6c": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "d224c6bfcf6f42e39aae5f1d68d481f2": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d5e7b3f112684b139268fa1cc5a5ec4c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e4a6da0543ab4c969e25739cd6d8fb19": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "ea9d45e43de941e7a7f42f4ae0203468": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "eb6b78bb4d8740c5960b68d1621831c0": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "f3f1fa83f1044d42bafb5aa42c862f66": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
